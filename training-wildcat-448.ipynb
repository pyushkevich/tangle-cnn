{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.0.0\n",
      "Torchvision Version:  0.2.1\n",
      "CUDA status:  True\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import sys\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "print(\"CUDA status: \", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import wildcat\n",
    "sys.path.append(\"wildcat.pytorch\")\n",
    "import wildcat.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top level data directory. Here we assume the format of the directory conforms\n",
    "#   to the ImageFolder structure\n",
    "data_dir = \"/home/pyushkevich/data/twoway\"\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 2\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 8\n",
    "\n",
    "# Number of epochs to train for\n",
    "num_epochs = 30\n",
    "\n",
    "# Input image size\n",
    "input_size = 448"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize wildcat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or use their initialization method\n",
    "model=wildcat.models.resnet50_wildcat(2, pretrained=True, kmax=0.2, alpha=0.7, num_maps=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.MultiLabelSoftMarginLoss()\n",
    "optimizer = torch.optim.SGD(model.get_config_optim(0.01, 0.1), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "# Transforms for training and validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomRotation(45),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Training and validation dataloaders\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Map model and criterior to device\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: \", device)\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard training code\n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                labels_one_hot = torch.zeros([labels.shape[0], 2])\n",
    "                labels_one_hot[:,0] = (labels==0)\n",
    "                labels_one_hot[:,1] = (labels==1)\n",
    "                labels_one_hot = labels_one_hot.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels_one_hot)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 0.4717 Acc: 0.7999\n",
      "val Loss: 0.2347 Acc: 0.9295\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 0.3489 Acc: 0.8723\n",
      "val Loss: 0.1889 Acc: 0.9361\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 0.2937 Acc: 0.8920\n",
      "val Loss: 0.2657 Acc: 0.9344\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.2705 Acc: 0.9062\n",
      "val Loss: 0.1958 Acc: 0.9393\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.2679 Acc: 0.9041\n",
      "val Loss: 0.2057 Acc: 0.9525\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.2505 Acc: 0.9041\n",
      "val Loss: 0.4650 Acc: 0.8590\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.2445 Acc: 0.9090\n",
      "val Loss: 0.1984 Acc: 0.9361\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.2549 Acc: 0.9095\n",
      "val Loss: 0.2349 Acc: 0.9180\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.2430 Acc: 0.9084\n",
      "val Loss: 0.1707 Acc: 0.9541\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.2048 Acc: 0.9260\n",
      "val Loss: 0.2058 Acc: 0.9459\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.2358 Acc: 0.9183\n",
      "val Loss: 0.2630 Acc: 0.9279\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.2298 Acc: 0.9205\n",
      "val Loss: 0.1863 Acc: 0.9492\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.2033 Acc: 0.9260\n",
      "val Loss: 0.2299 Acc: 0.9492\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.2160 Acc: 0.9194\n",
      "val Loss: 0.3188 Acc: 0.8918\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.2212 Acc: 0.9161\n",
      "val Loss: 0.1906 Acc: 0.9492\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.2091 Acc: 0.9232\n",
      "val Loss: 0.2093 Acc: 0.9377\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.2053 Acc: 0.9194\n",
      "val Loss: 0.2330 Acc: 0.9525\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.2134 Acc: 0.9265\n",
      "val Loss: 0.2032 Acc: 0.9295\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.1842 Acc: 0.9337\n",
      "val Loss: 0.1876 Acc: 0.9426\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.1919 Acc: 0.9337\n",
      "val Loss: 0.1714 Acc: 0.9574\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.2035 Acc: 0.9243\n",
      "val Loss: 0.2997 Acc: 0.9197\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.1960 Acc: 0.9211\n",
      "val Loss: 0.2222 Acc: 0.9361\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.1969 Acc: 0.9249\n",
      "val Loss: 0.2526 Acc: 0.9459\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.2064 Acc: 0.9189\n",
      "val Loss: 0.2056 Acc: 0.9475\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.1703 Acc: 0.9402\n",
      "val Loss: 0.2114 Acc: 0.9541\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.1757 Acc: 0.9359\n",
      "val Loss: 0.1872 Acc: 0.9525\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.2000 Acc: 0.9249\n",
      "val Loss: 0.1839 Acc: 0.9557\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.1638 Acc: 0.9359\n",
      "val Loss: 0.3722 Acc: 0.9033\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.1814 Acc: 0.9364\n",
      "val Loss: 0.3025 Acc: 0.9164\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.1651 Acc: 0.9359\n",
      "val Loss: 0.2693 Acc: 0.9492\n",
      "\n",
      "Training complete in 25m 29s\n",
      "Best val Acc: 0.957377\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft.state_dict(),\"/home/pyushkevich/resnet/my_wildcat_50_30epoch_k02_448.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
